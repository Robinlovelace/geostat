---
title: "Geostat 2015, Lancaster geostat-course.org slides"
output:
  html_document:
    toc: true
    theme: united
---

[CC-BY-SA](http://creativecommons.org/licenses/by-sa/4.0/), Edzer Pebesma 2015.

# Time, Space, Spacetime in R

\(
\newcommand{\E}{{\rm E}}       % E expectation operator
\newcommand{\Var}{{\rm Var}}   % Var variance operator
\newcommand{\Cov}{{\rm Cov}}   % Cov covariance operator
\newcommand{\Cor}{{\rm Corr}}
\)

## Data in R
Data in R are often organized in vectors,
```{r}
a = c(15, 20, 30)
a
b = c("blue", "brown", "blue")
b
```
in matrices
```{r}
m = matrix(1:4, 2, 2)
m
```
in `data.frame`s
```{r}
d = data.frame(a, b = c("blue", "brown", "brown"), c = c(65, 77, 69.6))
d
```
Such data has little meaning, because it is unclear what the variables
refer to, and what the records refer to. A more descriptive way would be
```{r}
Patients = data.frame(PatientID = a, EyeColor = b, Weight_kg = c(65, 77, 69.6))
Patients
```
where another table would be needed for the personal details related
to `PatientID`.

Note here that
 * records (rows in the `data.frame`) correspond to objects (persons), 
 * the variable `Weight_kg` has a [measurement unit](http://www.bipm.org/en/measurement-units/ "BIPM") encoded it its variable name

The weight numbers
```{r}
Patients$Weight_kg
```
carry no information about their measurement unit, allowing for meaningless computations such as
```{r}
with(Patients, Weight_kg + PatientID)
```
The answer is correct, though, as `+` requires two numeric arguments. If we try to add
eye color to body weight, we get a warning if `EyeColor` is a `factor` (by default,
`data.frame` converts `character` vectors into `factor`s!),
```{r}
with(Patients, EyeColor + Weight_kg)
```
or in case `EyeColor` is `character`, we get an error:
```{r}
Patients$EyeColor = as.character(Patients$EyeColor)
print(try(with(Patients, EyeColor + Weight_kg)))
```
Take home messages:

1. `data.frame` may change your information (convert character into `factor`), which
is useful for some purposes (categorical variables, models), but not for others (DNA sequences).
1. computations that are syntactically correct are not necessarily meaningful
1. *never ever* ignore errors or warnings, but drill down into where they come from
1. Records in a table (rows in a `data.frame`) often refer to *objects*, variables
(columns) often to properties of these objects.

Exercises

1. how can the `data.frame` command above be modified such that
the character variable is not modified into a `factor`?
1. how can R be configured such that this is always the case?
1. in a long script, warnings are printed at the end. How can
you make them print where they happen, or convert them into
errors? (hint: `?options`)

## Temporal data in R

### How do we represent time?

People communicate time by using words, which can be written down as character
information. Phrases like *Sunday, 16 Aug 2015* and *18:36* are widely understood
(although language dependent) to indicate date and time. Combined, we sometime see
```{r}
system("date > date.file")
readLines("date.file")
```
There are actually a lot of different ways in which we can represent
time information, and still understand it. For computers, this is less
easy.

### ISO 8601

[ISO 8601](https://en.wikipedia.org/wiki/ISO_8601) - *Data elements
and interchange formats - Information interchange - Representation
of dates and times* tries to create some order in this mess. It uses
e.g. `2015-08-07` for Aug 7 2015, and `2015-08-07T18:30:27+00:00`
to specify a given time and time zone on that date.

ISO 8601 implicitly defines time stamps to refer to
time *intervals*: 2015-08-07 refers to the *full day* of Aug 7, i.e.
from 2015-08-07 00:00 up to but not including 2015-08-08 00:00. The
time stamp 2015-08-07 00:00 has a duration of one second. 2015-08
refers to a full month.

### Who knows what time it is? 

Coordinated Universal Time
[UTC](https://en.wikipedia.org/wiki/International_Organization_for_Standardization "UTC")
``It is, within about 1 second, mean solar time at 0 degree
longitude; it does not observe daylight saving time.'' (formerly: GMT). It keeps track of
the Earth's rotation and International Atomic Time ([TAI](https://en.wikipedia.org/wiki/International_Atomic_Time)), by introducing leap seconds [now
and then](https://en.wikipedia.org/wiki/Leap_second).
Real-time approximations to UTC are broadcast wireless by GPS and
radio time signals; computers usually use the [network time
protocol](https://en.wikipedia.org/wiki/Network_Time_Protocol "NTP")
to synchronize clocks.

### Does R know all this?

Kind of - for instance 
```{r}
as.Date(.leap.seconds)
```
To find out what time it is, R of
course relies on the system clock. The R [source
code](https://stat.ethz.ch/pipermail/r-devel/2015-July/071472.html)
is updated every time a leap second is announced. It is based on
the code that operating systems use to handle date/time.

### Representing time in R

Although one could argue that time is represented by a real number
($\mathbb{R}$), for the sequence
```{r}
c(55, 60, 65, 70)
```
it is not clear to which point in time we refer to. Are these
years since 1900, or seconds since the start of Today? To fix this,
one needs to set an offset and a unit.

R has two built-in formats for this, `Date` and `POSIXt`:
```{r}
(d = Sys.Date())
class(d)
print(as.numeric(d), digits = 15)
(t = Sys.time())
class(t)
print(as.numeric(t), digits = 15)
```
`Date` is stored as the (integer) number of days since 1970-01-01
(in the local time zone), time is stored as the (fractional) number
of seconds since 1970-01-01 00:00 UTC. We can see that time is *printed*
in the current time zone.

R also ``understands'' time differences, e.g.
```{r}
d - (d+1)
d - (d+1.1)
t - (t+24*3600)
t - t+24*3600
```

Exercise

1. why do the last two expressions print a different result?

`POSIXct` uses one double to representation a time instance, `POSIXlt` represents time as a list (each time stamp one list), and is convenient to isolate time
components:
```{r}
t
(lt = as.POSIXlt(t))
unlist(lt)
sapply(lt, class)
lt$sec
```

Exercise

1. explain all the fields of a POSIXlt object

### Time zones in R

Time zones make it easy to understand whether it is day or night
without asking where you are, and take care of daylight saving time.
There is a [time zone database](https://www.iana.org/time-zones)
and a [wikipedia entry](https://en.wikipedia.org/wiki/Tz_database),
and R uses this either directly or through the GNU C library.

```{r}
Sys.setenv(TZ="CET")
as.POSIXct("2015-03-28") - as.POSIXct("2015-03-27") # regular
as.POSIXct("2015-03-30") - as.POSIXct("2015-03-29") # 23 hrs: DST starts
as.POSIXct("2015-10-26") - as.POSIXct("2015-10-25") # 25 hours: DST ends
```
whereas in UTC,
```{r}
Sys.setenv(TZ="UTC")
as.POSIXct("2015-03-30") - as.POSIXct("2015-03-29")
as.POSIXct("2015-10-26") - as.POSIXct("2015-10-25")
Sys.setenv(TZ="CET")
```
having irregular intervals (day lengths) makes it complicated
to compute daily means of e.g. hourly values; working with UTC
may solve this problem. Climate scientists often model climate
for years with 360 days, to get rid of the complexity of handling
unequal month lengths and leap years. 

### Reading time data into R

Date and time are understood from character strings (or factor)
when entered like this:
```{r}
as.Date("2015-08-17")
as.POSIXct("2015-08-17")
as.POSIXct("2015-08-17 12:25")
```
but not like this
```{r}
as.POSIXct("2015-08-07T18:30:27Z")
```
where everything after the T is ignored, without warning! 

Arbitrary time formats can be specified using `strptime`, e.g.
```{r}
strptime("2015-08-07T18:30:27Z", "%Y-%m-%dT%H:%M:%SZ", tz = "UTC")
```

The (implicit) interval information of ISO 8601 time expressions
is lost when read as POSIXt objects, as
```{r}
identical(as.POSIXct("2015-08-17"), as.POSIXct("2015-08-17 00:00"))
```

To convert numerical values into dates or time, the offset needs to
be specified:
```{r}
print(try(as.Date(365)))
as.Date(365, origin = "1970-01-01")
as.POSIXct(365 * 24 * 3600, origin = "1970-01-01")
```
although package zoo takes a somewhat different take on this:
```{r}
library(zoo)
as.Date(365)
```


### Packages with tools to deal with time

The CRAN [Time Series Analysis Task View](https://cran.uni-muenster.de/web/views/TimeSeries.html)
describes all packages dealing with time, time series data, and its analysis.
Several packages provide other ways of representing time; package [lubridate](https://cran.uni-muenster.de/web/packages/lubridate/index.html) for instance provides explicit representation of time intervals.

### Packages for analyzing time series data

The time series task view is complete here, but I will mention two important packages: [zoo](https://cran.uni-muenster.de/package=zoo) and [xts](https://cran.uni-muenster.de/package=xts).

Zoo is for ordered observations, where the ordering does not *have* to be time:
```{r}
library(zoo)
zoo(rnorm(10), 1:10)
```
it provides a lot of convenient functions, including `aggregate`, `na.fill`, and e.g. moving average filters. See for instance `?aggregate.zoo` for many examples aggregating time series to daily, monthly, quarterly or yearly values.

Package xts builds on top of zoo (xts is a subclass of zoo), and requires that data are ordered by time. It allows for different time classes (e.g. `Date` and `POSIXct`) but works with `POSIXct` under the hood. xts adds very convenient ISO 8601 style time interval selection:
```{r}
library(xts)
x = xts(1:365, as.Date("2015-01-01")+0:364)
nrow(x)
nrow(x["2015-05"]) # all days in May
nrow(x["2015-05/06"]) # all days in May and June
```

## Spatial data in R

### How far from home am I?
[Geonames](http://www.geonames.org/) is a gazetteer
(geographical dictionary or directory) that has a collection
of place names, place types and geographical coordinates in
[WGS84](https://en.wikipedia.org/wiki/World_Geodetic_System),
along with several other things.

You can register yourself at [geonames](http://www.geonames.org/login).
```{r eval=FALSE}
options(geonamesUsername = "edzer") # don't use my name!
library(geonames)
pts = rbind(
 LA = GNsearch(name = "Lancaster University", adminCode1 = "ENG"),
 MS = GNsearch(name = "Münster")[1,]
)[c("lng", "lat")]
```
```{r echo=FALSE}
load("pts.RData")
```
```{r}
pts
```

It turns out that `pts` is still filled with character information, 
```{r}
class(pts$lng)
```
so we need to transform it into numeric:
```{r}
pts = sapply(pts, as.numeric) # this drops rownames, so:
rownames(pts) = c("LA", "MS") # Lancaster, Muenster
pts
```
R has a function called `dist`, which computes (euclidean) distances in $\mathbb{R}^n$:
```{r}
dist(pts)
```
which returns `10.6`, but 10.6 what? Degrees? Nautical miles? Oranges? No,
plane nonsense, and `dist` is only useful for geographical coordinates (long/lat) in small areas close to the equator: our data are not in planar space, so we need to be more clever. 

### Package sp
Package `sp` provides classes for points, lines, polygons and grids which register their coordinate reference system (CRS), and chooses appropriate distance functions:
```{r}
library(sp)
pts = SpatialPoints(pts, CRS("+proj=longlat +datum=WGS84"))
spDists(pts) # km, great circle distance over the WGS84 ellipsoid
```
package [geosphere](https://cran.uni-muenster.de/package=geosphere) provides several alternative spherical/ellipsoidal distance measures:
```{r}
library(geosphere)
distHaversine(pts[1],pts[2])
distGeo(pts[1],pts[2]) # different from spDist:
spDists(pts)[2,1]*1000 - distGeo(pts[1],pts[2])  # difference in m
```

### Subsetting sp objects
as we have seen, a `SpatialPoints` object can be subsetted by its index, but
also by its row name; `pts[1]` and `pts[1,]` yield the same:
```{r}
pts[1]
pts[1,]
pts["MS"]
```

If we add attributes to `pts`, e.g. by
```{r}
pts$pop = c(299.708, 45.952) # according to Wikipedia
pts$area = c(302.9, 19.2) # I asked google
pts
```
we see that the class of `pts` now has changed from `SpatialPoints` to `SpatialPointsDataFrame`, the reason being that in addition to geometry (locations), the object now has attributes (in a `data.frame` slot). We can subset or manipulate these attributes in the same fashion as we can with plane `data.frame`s:
```{r}
pts["pop"]
pts[,"pop"]
pts[["pop"]]
pts$pop
pts[1,"pop"]
pts[1,]$pop
(pts$popDensity = pts$pop / pts$area)
```

We can even select using the spatial predicate *intersect*, as in
```{r}
library(spacetime)
data(air) # loads the boundary of Germany, called DE
proj4string(DE) = proj4string(pts) # they are semantically identical, but syntactically different
pts[DE,]
plot(DE, axes = TRUE)
points(pts[DE,], col = 'red', pch = 16)
```

## Spatiotemporal data in R

